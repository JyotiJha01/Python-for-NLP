{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ea0256-cb5b-418a-adf5-207eb13ff913",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "\n",
    "### Task: Classifying Names using RNN in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca060e67-7194-4971-bc1b-31542ae05ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-03 18:56:38--  https://download.pytorch.org/tutorial/data.zip\n",
      "Resolving download.pytorch.org (download.pytorch.org)... 108.158.61.54, 108.158.61.105, 108.158.61.120, ...\n",
      "Connecting to download.pytorch.org (download.pytorch.org)|108.158.61.54|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2882130 (2.7M) [application/zip]\n",
      "Saving to: ‘data.zip.1’\n",
      "\n",
      "data.zip.1          100%[===================>]   2.75M  7.51MB/s    in 0.4s    \n",
      "\n",
      "2024-08-03 18:56:39 (7.51 MB/s) - ‘data.zip.1’ saved [2882130/2882130]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "!wget https://download.pytorch.org/tutorial/data.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b68edb-4042-4417-9dba-05d6bf848cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7474aecf-52c6-4672-a33e-944edf823b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4973f233-9720-4cd5-b50e-a57e4a84ec97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters = string.ascii_letters + \".,:'\"\n",
    "n_letters = len(all_letters)\n",
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41529ab1-6349-4531-b07b-a98646fbb396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slusarski'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn a Unicode string to plain ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != \"Mn\" and c in all_letters ) # 'Mn' stands for \"Mark, Nonspacing\"\n",
    "\n",
    "unicodeToAscii('Ślusàrski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06a3ff31-8595-4b5a-9979-b453287636d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the all_names dictionary, a list of names per language\n",
    "all_names = []\n",
    "all_country =[]\n",
    "\n",
    "\n",
    "# Read a file and split into lines\n",
    "for f in os.listdir(\"data/names\"):\n",
    "    f1 = open('data/names/' + f, \"r\")\n",
    "    lis = f1.readlines()\n",
    "    clean_lis = list(map(unicodeToAscii, lis))\n",
    "    all_names.extend(clean_lis)\n",
    "    all_country.extend([f.split(\".\")[0]]* len(clean_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c67c3d-6279-47c2-8b34-76bb50fe2d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20074"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = len(all_names)\n",
    "n_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b2a1d-1fc3-4190-ab99-73b8a53a6844",
   "metadata": {},
   "source": [
    "### Turning Names into Tensors\n",
    "\n",
    "Now that we have all the names organized, we need to turn them into Tensors to make any use of them.\n",
    "\n",
    "To represent a single letter, we use a “one-hot vector” of size <1 x n_letters>. A one-hot vector is filled with 0s except for a 1 at index of the current letter, e.g. \"b\" = <0 1 0 0 0 ...>.\n",
    "\n",
    "To make a word we join a bunch of those into a 2D matrix <line_length x 1 x n_letters>.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes everything is in batches - we’re just using a batch size of 1 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b09898-83a5-431a-aabf-de368538ee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding \n",
    "emb = torch.eye(n_letters)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5729aa-c67c-452d-a0c4-224a67a00139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 56])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape     # [56,56] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bbce9d2-55f3-4631-be5b-76e9f5b271d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 0,\n",
       " 'Chinese': 1,\n",
       " 'Czech': 2,\n",
       " 'Dutch': 3,\n",
       " 'English': 4,\n",
       " 'French': 5,\n",
       " 'German': 6,\n",
       " 'Greek': 7,\n",
       " 'Irish': 8,\n",
       " 'Italian': 9,\n",
       " 'Japanese': 10,\n",
       " 'Korean': 11,\n",
       " 'Polish': 12,\n",
       " 'Portuguese': 13,\n",
       " 'Russian': 14,\n",
       " 'Scottish': 15,\n",
       " 'Spanish': 16,\n",
       " 'Vietnamese': 17}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = dict(zip(np.unique(all_country), range(n_rows)))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f8e671-1b43-4658-a6a4-f84062336b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.]]),\n",
       " tensor(3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding data\n",
    "def get_data(idx):\n",
    "    name = all_names[idx]\n",
    "    country = all_country[idx]\n",
    "    name_char_lis = np.array(list(name))\n",
    "    indices = np.where(name_char_lis[... , None] == np.array(list(all_letters)))[1]\n",
    "    return emb[torch.from_numpy(indices)], torch.tensor(mapping[country])\n",
    "\n",
    "get_data(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "796404d1-0111-4bb7-b9de-983317d815f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_data(idx)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e0ad802-f8fa-4eb0-b74d-628de1f2fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating the RNN network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_country, n_letters):\n",
    "        super(Net,self).__init__()\n",
    "        self.rnn = nn.RNN(n_letters, 2* n_letters) # input_size , hidden_size Wih = (56,112) Whh = (112,18)\n",
    "        self.fc = nn.Linear( 2 * n_letters, n_country)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out1 = self.fc(out[-1,:])\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f45cce80-a766-4765-ba5f-9e7fe277146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (rnn): RNN(56, 112)\n",
       "  (fc): Linear(in_features=112, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(len(np.unique(all_country)), n_letters)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "023edc6d-42dd-4af4-9d6f-065cc365581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_fc = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d10f0104-b9bf-467a-b08e-3128e5c7f446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.3542\n",
      "Epoch [2/20], Loss: 1.1727\n",
      "Epoch [3/20], Loss: 1.0782\n",
      "Epoch [4/20], Loss: 1.0187\n",
      "Epoch [5/20], Loss: 0.9753\n",
      "Epoch [6/20], Loss: 0.9414\n",
      "Epoch [7/20], Loss: 0.9079\n",
      "Epoch [8/20], Loss: 0.8789\n",
      "Epoch [9/20], Loss: 0.8504\n",
      "Epoch [10/20], Loss: 0.8280\n",
      "Epoch [11/20], Loss: 0.8048\n",
      "Epoch [12/20], Loss: 0.7855\n",
      "Epoch [13/20], Loss: 0.7676\n",
      "Epoch [14/20], Loss: 0.7509\n",
      "Epoch [15/20], Loss: 0.7339\n",
      "Epoch [16/20], Loss: 0.7192\n",
      "Epoch [17/20], Loss: 0.7048\n",
      "Epoch [18/20], Loss: 0.6917\n",
      "Epoch [19/20], Loss: 0.6757\n",
      "Epoch [20/20], Loss: 0.6616\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_epochs = 20\n",
    "all_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    arr = np.arange(n_rows)  # 0,1,2 --- 20074\n",
    "    np.random.shuffle(arr)\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for ind in arr:\n",
    "        data, target = get_data(ind)\n",
    "        output = model(data)\n",
    "        loss = loss_fc(output, target)\n",
    "        epoch_loss += loss.detach().numpy()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_epoch_loss = epoch_loss / n_rows\n",
    "    all_losses.append(average_epoch_loss)\n",
    "\n",
    "    # Print the current epoch and average loss for the epoch\n",
    "    print(f'Epoch [{epoch + 1}/{n_epochs}], Loss: {average_epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b9416-4e0a-4844-95fd-af48658b46d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
